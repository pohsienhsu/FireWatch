{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "from datetime import date, timedelta\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\Anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  STATE_NAME COUNTY_NAME  STATE_CODE  COUNTY_CODE        DATE  AQI CATEGORY  \\\n",
      "0    Alabama     Calhoun           1           15  1992-01-01   12     Good   \n",
      "1    Alabama     Calhoun           1           15  1992-01-07   28     Good   \n",
      "2    Alabama     Calhoun           1           15  1992-01-13    6     Good   \n",
      "3    Alabama     Calhoun           1           15  1992-01-19   12     Good   \n",
      "4    Alabama     Calhoun           1           15  1992-01-25   13     Good   \n",
      "\n",
      "  DEFINING_PARAMETER DEFINING_SITE  NUMBER_OF_SITES_REPORTING  YEAR  \n",
      "0               PM10   01-015-0001                          1  1992  \n",
      "1               PM10   01-015-0001                          1  1992  \n",
      "2               PM10   01-015-0001                          1  1992  \n",
      "3               PM10   01-015-0001                          1  1992  \n",
      "4               PM10   01-015-0001                          1  1992  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATE_NAME</th>\n",
       "      <th>COUNTY_CODE</th>\n",
       "      <th>DATE</th>\n",
       "      <th>AQI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>15</td>\n",
       "      <td>1992-01-01</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>15</td>\n",
       "      <td>1992-01-07</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>15</td>\n",
       "      <td>1992-01-13</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>15</td>\n",
       "      <td>1992-01-19</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>15</td>\n",
       "      <td>1992-01-25</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  STATE_NAME  COUNTY_CODE       DATE  AQI\n",
       "0    Alabama           15 1992-01-01   12\n",
       "1    Alabama           15 1992-01-07   28\n",
       "2    Alabama           15 1992-01-13    6\n",
       "3    Alabama           15 1992-01-19   12\n",
       "4    Alabama           15 1992-01-25   13"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in aqi master file\n",
    "aqi_df = pd.read_csv('datasets/aqi.csv', index_col = 0)\n",
    "print(aqi_df.head())\n",
    "# keep only the columns we absolutely need for efficiency\n",
    "aqi_df = aqi_df[[\"STATE_NAME\", \"COUNTY_CODE\", \"DATE\", \"AQI\"]]\n",
    "aqi_df[\"DATE\"] = pd.to_datetime(aqi_df[\"DATE\"], infer_datetime_format=True)\n",
    "aqi_df.reset_index(drop = True, inplace = True)\n",
    "aqi_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3049: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  FIRE_CODE       FIRE_NAME  FIRE_YEAR DISCOVERY_DATE  DISCOVERY_DOY  \\\n",
      "0                                                                      \n",
      "0      BEV0   TONSINA CREEK       2005     2005-04-28            118   \n",
      "1      BEV0  PETERSON CREEK       2005     2005-05-08            128   \n",
      "2      BEV0     TWENTY MILE       2005     2005-05-09            129   \n",
      "3      C63B       MOTORHOME       2007     2007-06-01            152   \n",
      "4      C63B           POWER       2007     2007-06-09            160   \n",
      "\n",
      "   DISCOVERY_TIME STAT_CAUSE_DESCR   CONT_DATE  CONT_DOY  CONT_TIME  ...  \\\n",
      "0                                                                    ...   \n",
      "0          1250.0         Campfire  2005-04-29     119.0     2100.0  ...   \n",
      "1          1715.0    Miscellaneous  2005-05-10     130.0     1800.0  ...   \n",
      "2           930.0   Debris Burning  2005-05-09     129.0     1030.0  ...   \n",
      "3          1415.0    Miscellaneous  2007-06-01     152.0     1640.0  ...   \n",
      "4          1430.0         Campfire  2007-06-09     160.0     1450.0  ...   \n",
      "\n",
      "    LATITUDE   LONGITUDE  OWNER_CODE       OWNER_DESCR  COUNTY COUNTY_CODE  \\\n",
      "0                                                                            \n",
      "0  60.053333 -149.440000        13.0  STATE OR PRIVATE   122.0         122   \n",
      "1  60.885000 -149.045000         5.0              USFS   122.0         122   \n",
      "2  60.861667 -148.995000        13.0  STATE OR PRIVATE   122.0         122   \n",
      "3  60.450278 -149.366944        13.0  STATE OR PRIVATE   122.0         122   \n",
      "4  60.466944 -149.700278         5.0              USFS   122.0         122   \n",
      "\n",
      "         FIPS_NAME  STATE_NAME      COUNTY_NAME STATE_CODE  \n",
      "0                                                           \n",
      "0  Kenai Peninsula      Alaska  Kenai Peninsula          2  \n",
      "1  Kenai Peninsula      Alaska  Kenai Peninsula          2  \n",
      "2  Kenai Peninsula      Alaska  Kenai Peninsula          2  \n",
      "3  Kenai Peninsula      Alaska  Kenai Peninsula          2  \n",
      "4  Kenai Peninsula      Alaska  Kenai Peninsula          2  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "Index(['FIRE_CODE', 'FIRE_NAME', 'FIRE_YEAR', 'DISCOVERY_DATE',\n",
      "       'DISCOVERY_DOY', 'DISCOVERY_TIME', 'STAT_CAUSE_DESCR', 'CONT_DATE',\n",
      "       'CONT_DOY', 'CONT_TIME', 'FIRE_SIZE', 'FIRE_SIZE_CLASS', 'LATITUDE',\n",
      "       'LONGITUDE', 'OWNER_CODE', 'OWNER_DESCR', 'COUNTY', 'COUNTY_CODE',\n",
      "       'FIPS_NAME', 'STATE_NAME', 'COUNTY_NAME', 'STATE_CODE'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATE_NAME</th>\n",
       "      <th>COUNTY_CODE</th>\n",
       "      <th>DISCOVERY_DATE</th>\n",
       "      <th>CONT_DATE</th>\n",
       "      <th>FIRE_CODE</th>\n",
       "      <th>FIRE_NAME</th>\n",
       "      <th>FIRE_SIZE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>122</td>\n",
       "      <td>2005-04-28</td>\n",
       "      <td>2005-04-29</td>\n",
       "      <td>BEV0</td>\n",
       "      <td>TONSINA CREEK</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>122</td>\n",
       "      <td>2005-05-08</td>\n",
       "      <td>2005-05-10</td>\n",
       "      <td>BEV0</td>\n",
       "      <td>PETERSON CREEK</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>122</td>\n",
       "      <td>2005-05-09</td>\n",
       "      <td>2005-05-09</td>\n",
       "      <td>BEV0</td>\n",
       "      <td>TWENTY MILE</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>122</td>\n",
       "      <td>2007-06-01</td>\n",
       "      <td>2007-06-01</td>\n",
       "      <td>C63B</td>\n",
       "      <td>MOTORHOME</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>122</td>\n",
       "      <td>2007-06-09</td>\n",
       "      <td>2007-06-09</td>\n",
       "      <td>C63B</td>\n",
       "      <td>POWER</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  STATE_NAME  COUNTY_CODE DISCOVERY_DATE  CONT_DATE FIRE_CODE       FIRE_NAME  \\\n",
       "0     Alaska          122     2005-04-28 2005-04-29      BEV0   TONSINA CREEK   \n",
       "1     Alaska          122     2005-05-08 2005-05-10      BEV0  PETERSON CREEK   \n",
       "2     Alaska          122     2005-05-09 2005-05-09      BEV0     TWENTY MILE   \n",
       "3     Alaska          122     2007-06-01 2007-06-01      C63B       MOTORHOME   \n",
       "4     Alaska          122     2007-06-09 2007-06-09      C63B           POWER   \n",
       "\n",
       "   FIRE_SIZE  \n",
       "0        2.3  \n",
       "1        2.5  \n",
       "2        0.1  \n",
       "3        0.1  \n",
       "4        0.1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in the fire data master file\n",
    "fire_df = pd.read_csv('datasets/fires.csv', index_col = 0)\n",
    "print(fire_df.head())\n",
    "print(fire_df.columns)\n",
    "# keep only needed columns for efficiency\n",
    "fire_df = fire_df[[\"STATE_NAME\", \"COUNTY_CODE\", \"DISCOVERY_DATE\", \"CONT_DATE\", \"FIRE_CODE\", \"FIRE_NAME\", \"FIRE_SIZE\"]]\n",
    "# turn datetimes into datetime objects\n",
    "fire_df[\"DISCOVERY_DATE\"] = pd.to_datetime(fire_df[\"DISCOVERY_DATE\"], infer_datetime_format=True)\n",
    "fire_df[\"CONT_DATE\"] = pd.to_datetime(fire_df[\"CONT_DATE\"], infer_datetime_format=True)\n",
    "# many fires have no cont date, set to disc date if this occurs\n",
    "no_cont = pd.isnull(fire_df[\"CONT_DATE\"])\n",
    "fire_df[\"CONT_DATE\"][no_cont] = fire_df[\"DISCOVERY_DATE\"][no_cont]\n",
    "fire_df.reset_index(drop = True, inplace = True)\n",
    "fire_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number Fires: 1201230\n",
      "At row 0 after 0.01 sec\n",
      "At row 100000 after 12.91 sec\n",
      "At row 200000 after 27.43 sec\n",
      "At row 300000 after 40.25 sec\n",
      "At row 400000 after 52.58 sec\n",
      "At row 500000 after 65.55 sec\n",
      "At row 600000 after 78.04 sec\n",
      "At row 700000 after 90.77 sec\n",
      "At row 800000 after 108.38 sec\n",
      "At row 900000 after 125.22 sec\n",
      "At row 1000000 after 141.81 sec\n",
      "At row 1100000 after 157.84 sec\n",
      "At row 1200000 after 174.26 sec\n"
     ]
    }
   ],
   "source": [
    "#make a dictionary which has a date as a key and returns indices of fire_df which are fires currently burning on that day\n",
    "fire_dict = dict()\n",
    "s = time.time()\n",
    "print(f\"Number Fires: {fire_df.shape[0]}\")\n",
    "for i in range(fire_df.shape[0]):\n",
    "    state_name = fire_df[\"STATE_NAME\"][i]\n",
    "    county_code = fire_df[\"COUNTY_CODE\"][i]\n",
    "    sdate = fire_df[\"DISCOVERY_DATE\"][i]\n",
    "    edate = fire_df[\"CONT_DATE\"][i]\n",
    "    delta = edate - sdate\n",
    "    for j in range(delta.days + 1):\n",
    "        day_date = sdate + timedelta(days=j)\n",
    "        key = (state_name, county_code, day_date)\n",
    "        if key not in fire_dict:\n",
    "            fire_dict[key] = {i}\n",
    "        else:\n",
    "            fire_dict[key].add(i)\n",
    "    if i % 100000 == 0:\n",
    "        print(f\"At row {i} after {time.time()-s:.2f} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1075591\n",
      "At row 0 after 0.00 sec\n",
      "At row 100000 after 4.80 sec\n",
      "At row 200000 after 9.22 sec\n",
      "At row 300000 after 13.27 sec\n",
      "At row 400000 after 19.51 sec\n",
      "At row 500000 after 24.09 sec\n",
      "At row 600000 after 29.26 sec\n",
      "At row 700000 after 38.36 sec\n",
      "At row 800000 after 42.87 sec\n",
      "At row 900000 after 47.65 sec\n",
      "At row 1000000 after 53.91 sec\n"
     ]
    }
   ],
   "source": [
    "# make a new dict which just has the count and sum\n",
    "fire_summary_dict = dict()\n",
    "s = time.time()\n",
    "print(len(fire_dict))\n",
    "for i, key in enumerate(fire_dict):\n",
    "    fires = fire_dict[key]\n",
    "    size = 0\n",
    "    for fire in fires:\n",
    "        size += fire_df[\"FIRE_SIZE\"][fire]\n",
    "    fire_summary_dict[key] = (len(fires), size)\n",
    "    if i%100000 == 0:\n",
    "        print(f\"At row {i} after {time.time() - s:.2f} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dict which is by state, date and does count and sum\n",
    "fire_summary_state_dict = dict()\n",
    "for s,c,d in fire_summary_dict:\n",
    "    count, sum = fire_summary_dict[(s,c,d)]\n",
    "    if (s,d) in fire_summary_state_dict:\n",
    "        count_c, sum_c = fire_summary_state_dict[(s,d)]\n",
    "        fire_summary_state_dict[(s,d)] =  (count_c + count, sum_c + sum)\n",
    "    else:\n",
    "        fire_summary_state_dict[(s,d)] =  (count, sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of AQI Entries 7243237\n",
      "At row 0 after 0.06 sec\n",
      "At row 100000 after 18.55 sec\n",
      "At row 200000 after 34.06 sec\n",
      "At row 300000 after 47.07 sec\n",
      "At row 400000 after 58.74 sec\n",
      "At row 500000 after 70.52 sec\n",
      "At row 600000 after 81.44 sec\n",
      "At row 700000 after 93.65 sec\n",
      "At row 800000 after 106.99 sec\n",
      "At row 900000 after 124.87 sec\n",
      "At row 1000000 after 148.47 sec\n",
      "At row 1100000 after 169.80 sec\n",
      "At row 1200000 after 182.28 sec\n",
      "At row 1300000 after 193.14 sec\n",
      "At row 1400000 after 206.27 sec\n",
      "At row 1500000 after 218.46 sec\n",
      "At row 1600000 after 230.82 sec\n",
      "At row 1700000 after 242.94 sec\n",
      "At row 1800000 after 254.03 sec\n",
      "At row 1900000 after 265.69 sec\n",
      "At row 2000000 after 276.20 sec\n",
      "At row 2100000 after 286.99 sec\n",
      "At row 2200000 after 297.95 sec\n",
      "At row 2300000 after 308.62 sec\n",
      "At row 2400000 after 318.57 sec\n",
      "At row 2500000 after 328.57 sec\n",
      "At row 2600000 after 338.43 sec\n",
      "At row 2700000 after 348.19 sec\n",
      "At row 2800000 after 359.73 sec\n",
      "At row 2900000 after 369.97 sec\n",
      "At row 3000000 after 379.23 sec\n",
      "At row 3100000 after 388.80 sec\n",
      "At row 3200000 after 398.25 sec\n",
      "At row 3300000 after 407.85 sec\n",
      "At row 3400000 after 417.76 sec\n",
      "At row 3500000 after 427.06 sec\n",
      "At row 3600000 after 436.75 sec\n",
      "At row 3700000 after 446.43 sec\n",
      "At row 3800000 after 455.77 sec\n",
      "At row 3900000 after 465.75 sec\n",
      "At row 4000000 after 475.69 sec\n",
      "At row 4100000 after 485.58 sec\n",
      "At row 4200000 after 495.44 sec\n",
      "At row 4300000 after 505.78 sec\n",
      "At row 4400000 after 515.76 sec\n",
      "At row 4500000 after 526.24 sec\n",
      "At row 4600000 after 536.28 sec\n",
      "At row 4700000 after 546.24 sec\n",
      "At row 4800000 after 559.33 sec\n",
      "At row 4900000 after 573.18 sec\n",
      "At row 5000000 after 583.93 sec\n",
      "At row 5100000 after 594.11 sec\n",
      "At row 5200000 after 605.65 sec\n",
      "At row 5300000 after 616.06 sec\n",
      "At row 5400000 after 626.40 sec\n",
      "At row 5500000 after 636.87 sec\n",
      "At row 5600000 after 647.72 sec\n",
      "At row 5700000 after 658.28 sec\n",
      "At row 5800000 after 668.48 sec\n",
      "At row 5900000 after 678.61 sec\n",
      "At row 6000000 after 689.03 sec\n",
      "At row 6100000 after 699.61 sec\n",
      "At row 6200000 after 709.86 sec\n",
      "At row 6300000 after 720.28 sec\n",
      "At row 6400000 after 730.31 sec\n",
      "At row 6500000 after 740.72 sec\n",
      "At row 6600000 after 751.26 sec\n",
      "At row 6700000 after 762.36 sec\n",
      "At row 6800000 after 774.80 sec\n",
      "At row 6900000 after 786.88 sec\n",
      "At row 7000000 after 799.77 sec\n",
      "At row 7100000 after 812.68 sec\n",
      "At row 7200000 after 825.13 sec\n"
     ]
    }
   ],
   "source": [
    "# for every row of the aqi dataset, get the count and sum of fires that were burning in that county on that day\n",
    "# and 1-num_weeks weeks prior, as well as the state on that day and 1-num_weeks weeks prior\n",
    "num_weeks = 3\n",
    "new_columns = np.zeros(shape=(num_weeks*4, aqi_df.shape[0]))\n",
    "\n",
    "s = time.time()\n",
    "print(f\"Number of AQI Entries {aqi_df.shape[0]}\")\n",
    "for i in range(aqi_df.shape[0]):\n",
    "    date = aqi_df[\"DATE\"][i]\n",
    "    state_name = aqi_df[\"STATE_NAME\"][i]\n",
    "    county_code = aqi_df[\"COUNTY_CODE\"][i]\n",
    "    for j in range(num_weeks):\n",
    "        offset_date = date - timedelta(days=j)\n",
    "        key = (state_name, county_code, offset_date)\n",
    "        if key in fire_summary_dict:\n",
    "            count, size = fire_summary_dict[key]\n",
    "            new_columns[j*4,i] = count\n",
    "            new_columns[j*4+1,i] = size\n",
    "        key = (state_name, offset_date)\n",
    "        if key in fire_summary_state_dict:\n",
    "            count, size = fire_summary_state_dict[key]\n",
    "            new_columns[j*4+2,i] = count\n",
    "            new_columns[j*4+3,i] = size\n",
    "    if i % 100000 == 0:\n",
    "        print(f\"At row {i} after {time.time() - s:.2f} sec\")\n",
    "for j in range(num_weeks):\n",
    "    aqi_df[f\"FIRES_COUNT_COUNTY_{j}_WEEK_PRIOR\"] = new_columns[j*4,:]\n",
    "    aqi_df[f\"FIRES_SIZE_COUNTY_{j}_WEEK_PRIOR\"] = new_columns[j*4+1,:]\n",
    "    aqi_df[f\"FIRES_COUNT_STATE_{j}_WEEK_PRIOR\"] = new_columns[j*4+2,:]\n",
    "    aqi_df[f\"FIRES_SIZE_STATE_{j}_WEEK_PRIOR\"] = new_columns[j*4+3,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 after 11.770874977111816\n",
      "2 after 19.447206735610962\n",
      "3 after 26.536211013793945\n"
     ]
    }
   ],
   "source": [
    "# add previous k AQI reads from the county, fill with oldest value otherwise (note this is just past readings not a set offset like 1 day (had issues with that))\n",
    "k = 3\n",
    "grouped_df = aqi_df.set_index('DATE').groupby(['STATE_NAME', 'COUNTY_CODE'])['AQI']\n",
    "s = time.time()\n",
    "for offset in range(1,k+1):\n",
    "    shifted = list(grouped_df.shift(offset))\n",
    "    aqi_df[f'AQI_{offset}_PRIOR'] = list(shifted)\n",
    "    col_name = 'AQI' if offset == 1 else f'AQI_{offset-1}_PRIOR'\n",
    "    aqi_df[f'AQI_{offset}_PRIOR'][pd.isnull(shifted)] = aqi_df[col_name][pd.isnull(shifted)]\n",
    "    print(f'{offset} after {time.time()-s}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1, 2, 3, 4, 5, 6, 7, -1, -7, -6, -5, -4, -3, -2}\n",
      "offset 1 done after 137.78314185142517\n",
      "offset 2 done after 282.34167408943176\n",
      "offset 3 done after 432.7793252468109\n",
      "offset 4 done after 581.7684490680695\n",
      "offset 5 done after 719.5824837684631\n",
      "offset 6 done after 865.196448802948\n",
      "offset 7 done after 1003.1694483757019\n",
      "offset -1 done after 1145.2144486904144\n",
      "offset -7 done after 1284.808448791504\n",
      "offset -6 done after 1424.7214517593384\n",
      "offset -5 done after 1568.4944524765015\n",
      "offset -4 done after 1706.270426750183\n",
      "offset -3 done after 1850.4874279499054\n",
      "offset -2 done after 1999.0944373607635\n"
     ]
    }
   ],
   "source": [
    "# add next days AQI\n",
    "offset = set(range(1,8)) | set(range(-1,-8,-1))\n",
    "print(offset)\n",
    "s = time.time()\n",
    "for i in offset:\n",
    "    next_day_aqi = []\n",
    "    for k,v in grouped_df:\n",
    "        for j in range(v.shape[0]):\n",
    "            next_day = v.index[j] + timedelta(days=i)\n",
    "            if next_day in v.index:\n",
    "                next_day_aqi.append(v[next_day])\n",
    "            else:\n",
    "                next_day_aqi.append(None)\n",
    "    print(f'offset {i} done after {time.time()-s}')\n",
    "    aqi_df[f'AQI_{i}_DAY_OFFSET'] = next_day_aqi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATE_NAME</th>\n",
       "      <th>COUNTY_CODE</th>\n",
       "      <th>DATE</th>\n",
       "      <th>AQI</th>\n",
       "      <th>FIRES_COUNT_COUNTY_0_WEEK_PRIOR</th>\n",
       "      <th>FIRES_SIZE_COUNTY_0_WEEK_PRIOR</th>\n",
       "      <th>FIRES_COUNT_STATE_0_WEEK_PRIOR</th>\n",
       "      <th>FIRES_SIZE_STATE_0_WEEK_PRIOR</th>\n",
       "      <th>FIRES_COUNT_COUNTY_1_WEEK_PRIOR</th>\n",
       "      <th>FIRES_SIZE_COUNTY_1_WEEK_PRIOR</th>\n",
       "      <th>...</th>\n",
       "      <th>AQI_5_DAY_OFFSET</th>\n",
       "      <th>AQI_6_DAY_OFFSET</th>\n",
       "      <th>AQI_7_DAY_OFFSET</th>\n",
       "      <th>AQI_-1_DAY_OFFSET</th>\n",
       "      <th>AQI_-7_DAY_OFFSET</th>\n",
       "      <th>AQI_-6_DAY_OFFSET</th>\n",
       "      <th>AQI_-5_DAY_OFFSET</th>\n",
       "      <th>AQI_-4_DAY_OFFSET</th>\n",
       "      <th>AQI_-3_DAY_OFFSET</th>\n",
       "      <th>AQI_-2_DAY_OFFSET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>15</td>\n",
       "      <td>1992-01-01</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>15</td>\n",
       "      <td>1992-01-07</td>\n",
       "      <td>28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>15</td>\n",
       "      <td>1992-01-13</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>15</td>\n",
       "      <td>1992-01-19</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>15</td>\n",
       "      <td>1992-01-25</td>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  STATE_NAME  COUNTY_CODE       DATE  AQI  FIRES_COUNT_COUNTY_0_WEEK_PRIOR  \\\n",
       "0    Alabama           15 1992-01-01   12                              0.0   \n",
       "1    Alabama           15 1992-01-07   28                              0.0   \n",
       "2    Alabama           15 1992-01-13    6                              0.0   \n",
       "3    Alabama           15 1992-01-19   12                              0.0   \n",
       "4    Alabama           15 1992-01-25   13                              0.0   \n",
       "\n",
       "   FIRES_SIZE_COUNTY_0_WEEK_PRIOR  FIRES_COUNT_STATE_0_WEEK_PRIOR  \\\n",
       "0                             0.0                             0.0   \n",
       "1                             0.0                             0.0   \n",
       "2                             0.0                             0.0   \n",
       "3                             0.0                             0.0   \n",
       "4                             0.0                             0.0   \n",
       "\n",
       "   FIRES_SIZE_STATE_0_WEEK_PRIOR  FIRES_COUNT_COUNTY_1_WEEK_PRIOR  \\\n",
       "0                            0.0                              0.0   \n",
       "1                            0.0                              0.0   \n",
       "2                            0.0                              0.0   \n",
       "3                            0.0                              0.0   \n",
       "4                            0.0                              0.0   \n",
       "\n",
       "   FIRES_SIZE_COUNTY_1_WEEK_PRIOR  ...  AQI_5_DAY_OFFSET  AQI_6_DAY_OFFSET  \\\n",
       "0                             0.0  ...               NaN              36.0   \n",
       "1                             0.0  ...               NaN              26.0   \n",
       "2                             0.0  ...               NaN              32.0   \n",
       "3                             0.0  ...               NaN              38.0   \n",
       "4                             0.0  ...               NaN              55.0   \n",
       "\n",
       "   AQI_7_DAY_OFFSET  AQI_-1_DAY_OFFSET  AQI_-7_DAY_OFFSET  AQI_-6_DAY_OFFSET  \\\n",
       "0               NaN                NaN                NaN                NaN   \n",
       "1               NaN                NaN                NaN                NaN   \n",
       "2               NaN                NaN                NaN               25.0   \n",
       "3               NaN                NaN                NaN               46.0   \n",
       "4               NaN                NaN                NaN               36.0   \n",
       "\n",
       "   AQI_-5_DAY_OFFSET  AQI_-4_DAY_OFFSET  AQI_-3_DAY_OFFSET  AQI_-2_DAY_OFFSET  \n",
       "0                NaN                NaN                NaN                NaN  \n",
       "1                NaN                NaN               25.0                NaN  \n",
       "2                NaN                NaN               46.0                NaN  \n",
       "3                NaN                NaN               36.0                NaN  \n",
       "4                NaN                NaN               26.0                NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#aqi_df = aqi_df.drop('AQI_3402_DAY_OFFSET',axis=1)\n",
    "aqi_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "aqi_df.to_csv('datasets/aqi_augmented.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
